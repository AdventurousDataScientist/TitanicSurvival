{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd663179",
   "metadata": {},
   "source": [
    "This model differs from base model in that it uses only the source data to make a prediction, doesnt remove or transform any variables, no feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53443bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f22cd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nikhil\\\\Developer\\\\Data_Science_Projects\\\\Titanic Survival'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91edb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be069cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.append('C:\\\\Users\\\\Nikhil\\\\Developer\\\\Data_Science_Projects')\n",
    "from common_ds_modules import missing_values, data_manipulation, modeling, eda\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from scipy.stats import skew\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d420623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MODELS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f089701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(df, query=''):\n",
    "    return [c for c in df.columns if query.lower() in c.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe8d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_cross_val_score(preprocessor, model, param_grid, x_train, y_train, scoring_function,max_models=None):\n",
    "    print(f'Max models: {max_models}')\n",
    "    if model.__name__ == 'Lasso' or model.__name__ == 'Ridge' or model.__name__ == 'ElasticNet':\n",
    "        print(f'Scaling Pipe: {model.__name__}')\n",
    "        pipe = make_pipeline(preprocessor, StandardScaler(), model())\n",
    "    else:\n",
    "        pipe = make_pipeline(preprocessor, model())\n",
    "    \n",
    "    if max_models is not None:\n",
    "        random_search = RandomizedSearchCV(pipe, param_grid, scoring=scoring_function,\n",
    "                                   n_iter=max_models, verbose=0)\n",
    "    else:\n",
    "        random_search = GridSearchCV(pipe, param_grid, scoring=scoring_function,\n",
    "                                   n_iter=max_models, verbose=0)\n",
    "\n",
    "    random_search = random_search.fit(x_train, y_train)\n",
    "    best_params = { k.split('__')[1]:v for (k,v) in zip(list(random_search.best_params_.keys()), list(random_search.best_params_.values()))} \n",
    "    if model.__name__ == 'Lasso' or model.__name__ == 'Ridge' or model.__name__ == 'ElasticNet':\n",
    "        print(f'Scaling Final Pipe: {model.__name__}')\n",
    "        final_pipe = final_pipe = make_pipeline(preprocessor, StandardScaler(), model(**best_params))\n",
    "    else:\n",
    "        final_pipe = make_pipeline(preprocessor, model(**best_params))\n",
    "    \n",
    "    score = cross_val_score(final_pipe, x_train, y_train, cv=5, scoring=scoring_function).mean()\n",
    "    \n",
    "    return final_pipe, score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad97fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'xgbclassifier__n_estimators': [110, 120],\n",
    "    'xgbclassifier__max_depth':[5,6],\n",
    "    'xgbclassifier__max_leaves':[40, 30, 50],\n",
    "    'xgbclassifier__reg_alpha': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__reg_lambda': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__colsample_bytree': [i/10 for i in range(2, 5)],\n",
    "    'xgbclassifier__learning_rate': [i/100 for i in range(3,6)],\n",
    "    'xgbclassifier__gamma': [i/100 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "lasso_param_grid = {\n",
    "    'lasso__alpha':[0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "ridge_param_grid = {\n",
    "    'ridge__alpha':[0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "elastic_net_param_grid = {\n",
    "    'elasticnet__alpha': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'elasticnet__l1_ratio':[0.01, 0.05, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'kneighborsclassifier__weights' : ['uniform'],\n",
    "    'kneighborsclassifier__algorithm' : ['auto'],\n",
    "    'kneighborsclassifier__n_neighbors' : [5,10,15, 20, 25, 30],\n",
    "    'kneighborsclassifier__leaf_size': [10],\n",
    "    'kneighborsclassifier__p': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36dd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14a4acd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a078caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Survived'\n",
    "y_train = train_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c0ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'PassengerId'\n",
    "pred_col = f'Predicted_{label}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4940fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables, categorical_variables = data_manipulation.get_numerical_categorical_variables(train_df,\\\n",
    "                                                                                            test_df, id_column)                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f9175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77c47175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_dist(df, variables):\n",
    "    for c in variables:\n",
    "        print(f'Variable: {c}')\n",
    "        display(df[c].describe())\n",
    "        plt.hist(df[c])\n",
    "        plt.title(f'Distribution for {c}')\n",
    "        plt.show()\n",
    "        \n",
    "def plot_discrete_variable_dist(df, variables):\n",
    "    for c in variables:\n",
    "        print(f'Variable: {c}')\n",
    "        display(df[c].value_counts(normalize=True))\n",
    "        plt.hist(df[c])\n",
    "        plt.title(f'Distribution for {c}')\n",
    "        plt.show()\n",
    "        \n",
    "def plot_cat_variable_dist(df, variables):\n",
    "    for c in variables:\n",
    "        print(f'Variable: {c}')\n",
    "        display(df[c].value_counts(normalize=True))\n",
    "        plt.bar(df[c].value_counts().index, df[c].value_counts())\n",
    "        plt.title(f'Distribution for {c}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20c74f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_train, y_train, x_test, model, id_col_name, id_col, pred_col, label, filename):\n",
    "    model = model.fit(x_train, y_train)\n",
    "    test_pred = model.predict(x_test)\n",
    "    \n",
    "    x_test[pred_col] = test_pred\n",
    "    x_test[id_col_name] = id_col\n",
    "    \n",
    "    pred = x_test[[id_col_name, pred_col]]\n",
    "    columns = dict()\n",
    "    columns[pred_col] = label\n",
    "    pred = pred.rename(columns=columns)\n",
    "    pred.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "781b0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>77.104377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>19.865320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.224467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column_name  percent_missing\n",
       "10        Cabin        77.104377\n",
       "5           Age        19.865320\n",
       "11     Embarked         0.224467\n",
       "0   PassengerId         0.000000\n",
       "1      Survived         0.000000\n",
       "2        Pclass         0.000000\n",
       "3          Name         0.000000\n",
       "4           Sex         0.000000\n",
       "6         SibSp         0.000000\n",
       "7         Parch         0.000000\n",
       "8        Ticket         0.000000\n",
       "9          Fare         0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_df = missing_values.get_variable_missing_values(train_df).reset_index(drop=True).sort_values('percent_missing', ascending=False)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb8bc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = train_df.copy()\n",
    "test_df2 = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1e62b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessor(train_df, id_column, label):\n",
    "    numerical_imputer = SimpleImputer(strategy='mean')\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    categorical_variables, discrete_numerical_variables,\\\n",
    "    continuous_numerical_variables = data_manipulation.get_variables(train_df, [], id_column)\n",
    "    discrete_numerical_variables = list(set(discrete_numerical_variables) - set([label])) \n",
    "    ind_continuous_variables = list(set(continuous_numerical_variables) - set([label]))\n",
    "    numerical_variables = continuous_numerical_variables + discrete_numerical_variables\n",
    "\n",
    "    categorical_columns_selector = selector(dtype_exclude='number')\n",
    "    categorical_columns = categorical_columns_selector(train_df)\n",
    "    categorical_columns = list(set(categorical_columns) - set([label]))\n",
    "    #categorical_columns = ['Embarked', 'Ticket', 'Sex', 'Cabin']\n",
    "    ohe2 = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    categorical_pipeline2 = make_pipeline(categorical_imputer, ohe2)\n",
    "    \n",
    "    print(f'Continuous Variables: {ind_continuous_variables}')\n",
    "    print(f'Discrete Numerical Variables: {discrete_numerical_variables}')\n",
    "    print(f'Categorical Variables: {categorical_columns}')\n",
    "    \n",
    "    preprocessor = make_column_transformer((categorical_pipeline2, categorical_columns),\n",
    "                                           (numerical_imputer, ind_continuous_variables),\n",
    "                                           (categorical_imputer, discrete_numerical_variables),\n",
    "                                        )\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e7d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stacking_classifier(train_df, y_train, estimators, final_estimator, scoring_function):\n",
    "    stacking_classifier = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=final_estimator,\n",
    "        )\n",
    "    \n",
    "    score = cross_val_score(stacking_classifier, train_df, y_train, cv=5, scoring=scoring_function).mean()\n",
    "    print(f'Score: {score}')\n",
    "    return stacking_classifier, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65596172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(preprocessor, train_df, y_train, dt_param_grid, rf_param_grid, knn_param_grid, xgb_param_grid,\\\n",
    "                    gbr_param_grid):\n",
    "    \n",
    "    dt_final_pipe, dt_score, dt_best_params = get_pipeline_cross_val_score(preprocessor, DecisionTreeClassifier,\\\n",
    "                                            dt_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'DT Score: {dt_score}, dt best params: {dt_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    rf_final_pipe, rf_score, rf_best_params = get_pipeline_cross_val_score(preprocessor, RandomForestClassifier,\\\n",
    "                                                            rf_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'RF Score: {rf_score}, RF best params: {rf_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    knn_final_pipe, knn_score, knn_best_params = get_pipeline_cross_val_score(preprocessor, KNeighborsClassifier,\\\n",
    "                                                knn_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'KNN Score: {knn_score}, KNN best params: {knn_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    xgb_final_pipe, xgb_score, xgb_best_params = get_pipeline_cross_val_score(preprocessor, XGBClassifier, xgb_param_grid,\\\n",
    "                                                train_df, y_train, 'accuracy', 50)\n",
    "    print(f'XGB Score: {xgb_score}, XGB best params: {xgb_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    gbr_final_pipe, gbr_score, gbr_best_params = get_pipeline_cross_val_score(preprocessor, GradientBoostingClassifier,\\\n",
    "                                                gbr_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'GBR Score: {gbr_score}, GBR best params: {gbr_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    lr_final_pipe = make_pipeline(preprocessor, LogisticRegression())\n",
    "    lr_score = cross_val_score(lr_final_pipe, train_df, y_train, cv=5, scoring='accuracy').mean()\n",
    "    print(f'Logistic Regression Score: {lr_score}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    return {'DecisionTree': dt_final_pipe, 'RandomForest': rf_final_pipe, 'KNN': knn_final_pipe, 'XGB': xgb_final_pipe,\\\n",
    "            'GBR': gbr_final_pipe, 'LogisticRegression': lr_final_pipe }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcce4f2",
   "metadata": {},
   "source": [
    "Code to train stack classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ed0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_param_grid = {\n",
    "    'decisiontreeclassifier__max_depth':[2,3],\n",
    "    'decisiontreeclassifier__min_samples_split':[10, 20, 30],\n",
    "    'decisiontreeclassifier__min_samples_leaf':[10, 20, 30],\n",
    "    'decisiontreeclassifier__max_features' : ['sqrt'],\n",
    "    'decisiontreeclassifier__min_impurity_decrease': [i/100 for i in range(1, 3)],\n",
    "    'decisiontreeclassifier__ccp_alpha': [i/10 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators':[100, 500, 1000],\n",
    "    'randomforestclassifier__min_samples_split':[10, 20, 30, 40, 50],\n",
    "    'randomforestclassifier__max_depth': [2,3,4,5],\n",
    "    'randomforestclassifier__min_samples_leaf': [5, 10, 15, 20, 25, 30],\n",
    "    'randomforestclassifier__min_impurity_decrease': [0.002, 0.004, 0.006, 0.008]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'kneighborsclassifier__weights' : ['uniform'],\n",
    "    'kneighborsclassifier__algorithm' : ['auto'],\n",
    "    'kneighborsclassifier__n_neighbors' : [5,10,15, 20, 25, 30],\n",
    "    'kneighborsclassifier__leaf_size': [10],\n",
    "    'kneighborsclassifier__p': [1],\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'xgbclassifier__n_estimators': [110, 120],\n",
    "    'xgbclassifier__max_depth':[5,6],\n",
    "    'xgbclassifier__max_leaves':[40, 30, 50],\n",
    "    'xgbclassifier__reg_alpha': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__reg_lambda': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__colsample_bytree': [i/10 for i in range(2, 5)],\n",
    "    'xgbclassifier__learning_rate': [i/100 for i in range(3,6)],\n",
    "    'xgbclassifier__gamma': [i/100 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "gbr_param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [1000, 1200],\n",
    "    'gradientboostingclassifier__max_depth':[4,5,6],\n",
    "    'gradientboostingclassifier__max_leaf_nodes':[40, 30, 50],\n",
    "    'gradientboostingclassifier__min_samples_split':[40, 30, 50],\n",
    "    'gradientboostingclassifier__subsample': [i/10 for i in range(2, 5)],\n",
    "    'gradientboostingclassifier__learning_rate': [i/100 for i in range(3,6)],\n",
    "    'gradientboostingclassifier__max_features': [i/100 for i in range(1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b183c",
   "metadata": {},
   "source": [
    "#### Base KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a35a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(train_df3, y_train, test_df3, knn_final_pipe, id_column, pred_col, label, 'knn_clf_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0952660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(worksheet, row_index):\n",
    "    num_rows = worksheet.max_row\n",
    "    num_cols = worksheet.max_column\n",
    "    headers = []\n",
    "    for i in range(row_index, row_index + 1):\n",
    "        for j in range(1, num_cols + 1):\n",
    "            cell = worksheet.cell(row=i, column=j)\n",
    "            if cell.value:\n",
    "                #print(f'Cell at ({i}, {j}): {cell.value}')\n",
    "                headers.append(cell.value)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56ba45",
   "metadata": {},
   "source": [
    "change it to use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf0fbdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(workbook, worksheet_name, data, row_index, workbook_title):\n",
    "    worksheet = workbook[worksheet_name]\n",
    "    current_row = worksheet.max_row + 1\n",
    "    headers = get_headers(worksheet, row_index)\n",
    "    num_cols = len(headers)\n",
    "    print(f'Num columns: {num_cols}')\n",
    "    print(f'current row: {current_row}')\n",
    "    cell = worksheet.cell(row=current_row - 1, column=1)\n",
    "    prev_version = 0\n",
    "    if cell.value != 'Version':\n",
    "        current_version = cell.value + 1\n",
    "        current_cell = worksheet.cell(row=current_row, column=1)\n",
    "        current_cell.value = current_version\n",
    "    else:\n",
    "        current_cell = worksheet.cell(row=current_row, column=1)\n",
    "        current_cell.value = 1\n",
    "        \n",
    "    for j in range(2, num_cols + 1):\n",
    "        cell = worksheet.cell(row=current_row, column=j)\n",
    "        cell.value = str(list(data.values())[j - 3])\n",
    "        print(f'Current Row = {current_row}, current column: {j}, cell_value: {cell.value}')\n",
    "    workbook.save(workbook_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ed374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(preprocessor, model, hyper_parameter_set, train_df, y_train, scoring_function, max_models,\\\n",
    "                         workbook, worksheet_name, workbook_name):\n",
    "    \n",
    "    final_pipe, train_score, best_params = get_pipeline_cross_val_score(preprocessor, model,\\\n",
    "                                            hyper_parameter_set, train_df, y_train, scoring_function, max_models)\n",
    "    \n",
    "    data = dict()\n",
    "    feature_list = list(train_df.columns)\n",
    "    feature_str = ',\\n '.join(feature_list)\n",
    "    \n",
    "    print(f'train_score: {train_score}')\n",
    "    \n",
    "    #workbook_name = 'Titanic Survival Model.xlsx'\n",
    "    sheet = pd.read_excel(workbook_name, sheet_name=worksheet_name).rename(columns=lambda x: x.strip())\n",
    "    \n",
    "    if len(sheet) > 0:\n",
    "        old_version = sheet.loc[len(sheet) - 1, 'Version']\n",
    "        new_version = old_version + 1\n",
    "    else:\n",
    "        new_version = 1\n",
    "        \n",
    "    public_score = 0\n",
    "    sheet.loc[len(sheet)] = [new_version, feature_str, hyper_parameter_set, best_params, train_score, public_score] # row\n",
    "\n",
    "    with pd.ExcelWriter(workbook_name,\n",
    "                        mode='a', if_sheet_exists='replace') as writer:  \n",
    "        sheet.to_excel(writer, sheet_name=worksheet_name, index=False)\n",
    "    #row_index = 1\n",
    "    #save_results(workbook, worksheet_name, data, row_index, workbook_name)\n",
    "    \n",
    "    return final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1e31503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(obj, query=''):\n",
    "    for field in dir(obj):\n",
    "        if field[0:2] != '__' and field[0] != '_':\n",
    "            if query.lower() in field.lower():\n",
    "                print(f'Field: {field}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9325f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_columns(train_df, label):\n",
    "    categorical_columns_selector = selector(dtype_exclude='number')\n",
    "    categorical_columns = categorical_columns_selector(train_df)\n",
    "    categorical_columns = list(set(categorical_columns) - set([label]))\n",
    "    \n",
    "    return categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ebd1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_variables(train_df, id_column, label):\n",
    "    categorical_variables, discrete_numerical_variables,\\\n",
    "    continuous_numerical_variables = data_manipulation.get_variables(train_df, [], id_column)\n",
    "    discrete_numerical_variables = list(set(discrete_numerical_variables) - set([label])) \n",
    "    ind_continuous_variables = list(set(continuous_numerical_variables) - set([label]))\n",
    "    \n",
    "    return ind_continuous_variables, discrete_numerical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e35a85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_continuous_variables, discrete_numerical_variables = get_numerical_variables(train_df2, id_column, label)\n",
    "categorical_columns = get_categorical_columns(train_df2, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08aa3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = categorical_columns + ind_continuous_variables + discrete_numerical_variables\n",
    "train_df3 = train_df2[variables]\n",
    "test_df3 = test_df2[variables]\n",
    "test_df3[id_column] = test_df2[id_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe0218de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Fare', 'Age']\n",
      "Discrete Numerical Variables: ['Parch', 'SibSp', 'Pclass']\n",
      "Categorical Variables: ['Name', 'Sex', 'Cabin', 'Ticket', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "preprocessor = get_preprocessor(train_df3, id_column, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c1a8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = 'useless variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efc3505d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.6878601468834349\n",
      "CPU times: total: 4.77 s\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_final_pipe = train_classifier(preprocessor, DecisionTreeClassifier, dt_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'DecisionTree', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdd578e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.6161634548992531\n",
      "CPU times: total: 1min 17s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_final_pipe = train_classifier(preprocessor, RandomForestClassifier, rf_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'RandomForest', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16926352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.746368715083799\n",
      "CPU times: total: 5.89 s\n",
      "Wall time: 3.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_final_pipe = train_classifier(preprocessor, KNeighborsClassifier, knn_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'KNN', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a91cd72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.8260372857949909\n",
      "CPU times: total: 1min 57s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbr_final_pipe = train_classifier(preprocessor, GradientBoostingClassifier, gbr_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'GBRClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d190399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.8440148138848785\n",
      "CPU times: total: 7min 55s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_final_pipe = train_classifier(preprocessor, XGBClassifier, xgb_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'XGBClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ce288",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b093e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_married(x):\n",
    "    return 1 if 'mrs.' in x['Name'].lower() and x['Sex'] == 'female' else 0\n",
    "\n",
    "def get_title(x):\n",
    "    return x.split(', ')[1].split(' ')[0]\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def convert_title(title):\n",
    "    if title not in ['Mr.', 'Miss.', 'Mrs.', 'Master']:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e91955ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4 = pd.read_csv('train.csv')\n",
    "test_df4 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39e4ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4['is_married'] = train_df4.apply(lambda x: is_married(x), axis='columns')\n",
    "train_df4['title'] = train_df4['Name'].apply(lambda x: get_title(x))\n",
    "train_df4['title_converted'] = train_df4['title'].apply(lambda x: convert_title(x))\n",
    "train_df4['sex_converted'] = train_df4['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "train_df4['age_group'] = train_df4['Age'].apply(lambda x: get_age_group(x))\n",
    "train_df4['family_size'] = train_df4['Parch'] + train_df4['SibSp']\n",
    "train_df4['solo_traveler'] = train_df4['family_size'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f96090ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df4['is_married'] = test_df4.apply(lambda x: is_married(x), axis='columns')\n",
    "test_df4['title'] = test_df4['Name'].apply(lambda x: get_title(x))\n",
    "test_df4['title_converted'] = test_df4['title'].apply(lambda x: convert_title(x))\n",
    "test_df4['sex_converted'] = test_df4['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "test_df4['age_group'] = test_df4['Age'].apply(lambda x: get_age_group(x))\n",
    "test_df4['family_size'] = test_df4['Parch'] + test_df4['SibSp']\n",
    "test_df4['solo_traveler'] = test_df4['family_size'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aad475b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nec_variables = ['Pclass', 'Embarked', 'Fare','is_married', 'title_converted', 'sex_converted', 'age_group', 'Age', 'family_size', 'solo_traveler', 'Parch', 'SibSp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6597a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df5 = train_df4[nec_variables]\n",
    "test_df5 = test_df4[nec_variables]\n",
    "y_train = train_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c41dd0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Fare', 'Age']\n",
      "Discrete Numerical Variables: ['family_size', 'Pclass', 'is_married', 'sex_converted', 'age_group', 'SibSp', 'solo_traveler', 'Parch']\n",
      "Categorical Variables: ['Embarked', 'title_converted']\n"
     ]
    }
   ],
   "source": [
    "preprocessor2 = get_preprocessor(train_df5, id_column, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b07efb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(['Fare', 'Age'] + ['is_married', 'solo_traveler', 'sex_converted', 'family_size', 'SibSp', 'age_group', 'Pclass', 'Parch'] + ['Embarked', 'title_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc66405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.6802083987194777\n",
      "CPU times: total: 2.09 s\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_final_pipe = train_classifier(preprocessor2, DecisionTreeClassifier, dt_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'DecisionTree', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "292a99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.8204004770573097\n",
      "CPU times: total: 1min 13s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_final_pipe = train_classifier(preprocessor2, RandomForestClassifier, rf_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'RandomForest', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98d8f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.7497520557403805\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_final_pipe = train_classifier(preprocessor2, KNeighborsClassifier, knn_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'KNN', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9027355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.8384093904965162\n",
      "CPU times: total: 1min 45s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_final_pipe = train_classifier(preprocessor2, XGBClassifier, xgb_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'XGBClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1e2e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.8249325214989642\n",
      "CPU times: total: 1min 57s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbr_final_pipe = train_classifier(preprocessor2, GradientBoostingClassifier, gbr_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'GBRClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f3db717",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final_pipe = make_pipeline(preprocessor2, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6554fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    " estimators = [\n",
    "        ('LogisticRegression', lr_final_pipe),\n",
    "         ('KNN', knn_final_pipe),\n",
    "        ('RandomForest', rf_final_pipe),\n",
    "        ('GradientBoostingClassifier', gbr_final_pipe),\n",
    "        ('XGBClassifier', xgb_final_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29882522",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_estimator = RandomForestClassifier()\n",
    "xgb_final_estimator = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "470807b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8136777352331931\n"
     ]
    }
   ],
   "source": [
    "rf_stack, rf_stack_score = train_stacking_classifier(train_df5, y_train, estimators, rf_final_estimator, 'accuracy')\n",
    "#predict(train_df5, y_train, test_df5, rf_stack, id_column,test_df[id_column], pred_col, label, 'rf_stack_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90538fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7867553825874081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7867553825874081"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_stack, xgb_stack_score = train_stacking_classifier(train_df5, y_train, estimators, xgb_final_estimator, 'accuracy')\n",
    "xgb_stack_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65a42535",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, xgb_stack, id_column, test_df[id_column], pred_col, label, 'xgb_stack_feat_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2ca82",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2403d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier with RF score: 0.8327663046889711\n"
     ]
    }
   ],
   "source": [
    "vote_rf = VotingClassifier(estimators=[('LogisticRegression', lr_final_pipe),\\\n",
    "                                         ('KNN', knn_final_pipe),\n",
    "                                         ('RF', rf_final_pipe),\n",
    "                                        ('GBR', gbr_final_pipe),\n",
    "                                        ('XGB', xgb_final_pipe)], voting='hard')\n",
    "\n",
    "score = cross_val_score(vote_rf, train_df5, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f'Voting Classifier with RF score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0725cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, vote_rf, id_column, test_df[id_column], pred_col, label, 'vote_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a947cd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Embarked', 'Fare', 'is_married', 'title_converted',\n",
       "       'sex_converted', 'age_group', 'Age', 'family_size', 'solo_traveler',\n",
       "       'Parch', 'SibSp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec00b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    " estimators_no_rf = [\n",
    "        ('LogisticRegression', lr_final_pipe),\n",
    "         ('KNN', knn_final_pipe),\n",
    "        ('GradientBoostingClassifier', gbr_final_pipe),\n",
    "        ('XGBClassifier', xgb_final_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f32c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7935095097608437\n"
     ]
    }
   ],
   "source": [
    "rf_stack_no_rf, rf_stack_score = train_stacking_classifier(train_df5, y_train, estimators_no_rf, rf_final_estimator, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87e055a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7699391124223212\n"
     ]
    }
   ],
   "source": [
    "xgb_stack_no_rf, xgb_stack_score = train_stacking_classifier(train_df5, y_train, estimators_no_rf, xgb_final_estimator, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e28f267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, rf_stack_no_rf, id_column,test_df[id_column], pred_col, label, 'rf_stack_no_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8763d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, xgb_stack_no_rf, id_column,test_df[id_column], pred_col, label, 'xgb_stack_no_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1da39489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier with no RF score: 0.8238026489234824\n"
     ]
    }
   ],
   "source": [
    "vote_no_rf = VotingClassifier(estimators=[('LogisticRegression', lr_final_pipe),\\\n",
    "                                         ('KNN', knn_final_pipe),\n",
    "                                        ('GBR', gbr_final_pipe),\n",
    "                                        ('XGB', xgb_final_pipe)], voting='hard')\n",
    "\n",
    "score = cross_val_score(vote_no_rf, train_df5, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f'Voting Classifier with no RF score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00ad2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, vote_no_rf, id_column, test_df[id_column], pred_col, label, 'vote_no_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b58af6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Embarked', 'Fare', 'is_married', 'title_converted',\n",
       "       'sex_converted', 'age_group', 'Age', 'family_size', 'solo_traveler',\n",
       "       'Parch', 'SibSp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14b6241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df6 = train_df4[nec_variables + ['Name', 'Ticket', 'Cabin']]\n",
    "test_df6 = test_df4[nec_variables + ['Name', 'Ticket', 'Cabin']]\n",
    "y_train = train_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f75d1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Fare', 'Age']\n",
      "Discrete Numerical Variables: ['family_size', 'Pclass', 'is_married', 'sex_converted', 'age_group', 'SibSp', 'solo_traveler', 'Parch']\n",
      "Categorical Variables: ['Name', 'title_converted', 'Cabin', 'Ticket', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "preprocessor3 = get_preprocessor(train_df6, id_column, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a1ce4",
   "metadata": {},
   "source": [
    "#### Using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b14994b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.6532421065846463\n",
      "Max models: 50\n",
      "train_score: 0.6161634548992531\n",
      "Max models: 50\n",
      "train_score: 0.7564873517042245\n",
      "Max models: 50\n",
      "train_score: 0.8417676228736426\n",
      "Max models: 50\n",
      "train_score: 0.8271671583704727\n",
      "CPU times: total: 13min 15s\n",
      "Wall time: 6min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_final_pipe = train_classifier(preprocessor3, DecisionTreeClassifier, dt_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'DecisionTree', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "rf_final_pipe = train_classifier(preprocessor3, RandomForestClassifier, rf_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'RandomForest', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "knn_final_pipe = train_classifier(preprocessor3, KNeighborsClassifier, knn_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'KNN', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "xgb_final_pipe = train_classifier(preprocessor3, XGBClassifier, xgb_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'XGBClassifier', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "gbr_final_pipe = train_classifier(preprocessor3, GradientBoostingClassifier, gbr_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'GBRClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61376621",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final_pipe = make_pipeline(preprocessor3, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d29a12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    " estimators = [\n",
    "        ('LogisticRegression', lr_final_pipe),\n",
    "         ('KNN', knn_final_pipe),\n",
    "        ('RandomForest', rf_final_pipe),\n",
    "        ('GradientBoostingClassifier', gbr_final_pipe),\n",
    "        ('XGBClassifier', xgb_final_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f7b4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_estimator = RandomForestClassifier()\n",
    "xgb_final_estimator = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9bf8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8148578243675851\n"
     ]
    }
   ],
   "source": [
    "rf_stack, rf_stack_score = train_stacking_classifier(train_df6, y_train, estimators, rf_final_estimator, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77915d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df6, y_train, test_df6, rf_stack, id_column, test_df[id_column], pred_col, label, 'rf_stack_feat_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e91e4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier with RF score: 0.8338710689849979\n"
     ]
    }
   ],
   "source": [
    "vote_rf = VotingClassifier(estimators=[('LogisticRegression', lr_final_pipe),\\\n",
    "                                         ('KNN', knn_final_pipe),\n",
    "                                           ('RF', rf_final_pipe),\n",
    "                                        ('GBR', gbr_final_pipe),\n",
    "                                        ('XGB', xgb_final_pipe)], voting='hard')\n",
    "\n",
    "score = cross_val_score(vote_rf, train_df6, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f'Voting Classifier with RF score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2332d3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [&#x27;Name&#x27;, &#x27;title_converted&#x27;,\n",
       "                                                   &#x27;Cabin&#x27;, &#x27;Ticket&#x27;,\n",
       "                                                   &#x27;Embarked&#x27;]),\n",
       "                                                 (&#x27;simpleimputer-1&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;]),\n",
       "                                                 (&#x27;simpleimputer-2&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;),\n",
       "                                                  [&#x27;family_size&#x27;, &#x27;Pclass&#x27;,\n",
       "                                                   &#x27;is_married&#x27;,\n",
       "                                                   &#x27;sex_converted&#x27;, &#x27;age_group&#x27;,\n",
       "                                                   &#x27;SibSp&#x27;, &#x27;solo_traveler&#x27;,\n",
       "                                                   &#x27;Parch&#x27;])])),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [&#x27;Name&#x27;, &#x27;title_converted&#x27;,\n",
       "                                                   &#x27;Cabin&#x27;, &#x27;Ticket&#x27;,\n",
       "                                                   &#x27;Embarked&#x27;]),\n",
       "                                                 (&#x27;simpleimputer-1&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;]),\n",
       "                                                 (&#x27;simpleimputer-2&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;),\n",
       "                                                  [&#x27;family_size&#x27;, &#x27;Pclass&#x27;,\n",
       "                                                   &#x27;is_married&#x27;,\n",
       "                                                   &#x27;sex_converted&#x27;, &#x27;age_group&#x27;,\n",
       "                                                   &#x27;SibSp&#x27;, &#x27;solo_traveler&#x27;,\n",
       "                                                   &#x27;Parch&#x27;])])),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 [&#x27;Name&#x27;, &#x27;title_converted&#x27;, &#x27;Cabin&#x27;, &#x27;Ticket&#x27;,\n",
       "                                  &#x27;Embarked&#x27;]),\n",
       "                                (&#x27;simpleimputer-1&#x27;, SimpleImputer(),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;]),\n",
       "                                (&#x27;simpleimputer-2&#x27;,\n",
       "                                 SimpleImputer(strategy=&#x27;most_frequent&#x27;),\n",
       "                                 [&#x27;family_size&#x27;, &#x27;Pclass&#x27;, &#x27;is_married&#x27;,\n",
       "                                  &#x27;sex_converted&#x27;, &#x27;age_group&#x27;, &#x27;SibSp&#x27;,\n",
       "                                  &#x27;solo_traveler&#x27;, &#x27;Parch&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Name&#x27;, &#x27;title_converted&#x27;, &#x27;Cabin&#x27;, &#x27;Ticket&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">simpleimputer-1</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">simpleimputer-2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;family_size&#x27;, &#x27;Pclass&#x27;, &#x27;is_married&#x27;, &#x27;sex_converted&#x27;, &#x27;age_group&#x27;, &#x27;SibSp&#x27;, &#x27;solo_traveler&#x27;, &#x27;Parch&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  ['Name', 'title_converted',\n",
       "                                                   'Cabin', 'Ticket',\n",
       "                                                   'Embarked']),\n",
       "                                                 ('simpleimputer-1',\n",
       "                                                  SimpleImputer(),\n",
       "                                                  ['Fare', 'Age']),\n",
       "                                                 ('simpleimputer-2',\n",
       "                                                  SimpleImputer(strategy='most_frequent'),\n",
       "                                                  ['family_size', 'Pclass',\n",
       "                                                   'is_married',\n",
       "                                                   'sex_converted', 'age_group',\n",
       "                                                   'SibSp', 'solo_traveler',\n",
       "                                                   'Parch'])])),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7baf530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df6, y_train, test_df6, vote_rf, id_column, test_df[id_column], pred_col, label, 'vote_feat_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37ab5044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Embarked', 'Fare', 'is_married', 'title_converted',\n",
       "       'sex_converted', 'age_group', 'Age', 'family_size', 'solo_traveler',\n",
       "       'Parch', 'SibSp', 'Name', 'Ticket', 'Cabin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74ee7049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pclass,\\n Embarked,\\n Fare,\\n is_married,\\n title_converted,\\n sex_converted,\\n age_group,\\n Age,\\n family_size,\\n solo_traveler,\\n Parch,\\n SibSp,\\n Name,\\n Ticket,\\n Cabin'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = list(train_df6.columns)\n",
    "feature_str = ',\\n '.join(feature_list)\n",
    "feature_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dece3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
