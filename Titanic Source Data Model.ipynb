{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd663179",
   "metadata": {},
   "source": [
    "This model differs from base model in that it uses only the source data to make a prediction, doesnt remove or transform any variables, no feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53443bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be069cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.append('C:\\\\Users\\\\Nikhil\\\\Data_Science_Projects')\n",
    "from common_ds_modules import missing_values, data_manipulation, modeling, eda\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from scipy.stats import skew\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d420623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MODELS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f089701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(df, query=''):\n",
    "    return [c for c in df.columns if query.lower() in c.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbe8d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_cross_val_score(preprocessor, model, param_grid, x_train, y_train, scoring_function,max_models=None):\n",
    "    print(f'Max models: {max_models}')\n",
    "    if model.__name__ == 'Lasso' or model.__name__ == 'Ridge' or model.__name__ == 'ElasticNet':\n",
    "        print(f'Scaling Pipe: {model.__name__}')\n",
    "        pipe = make_pipeline(preprocessor, StandardScaler(), model())\n",
    "    else:\n",
    "        pipe = make_pipeline(preprocessor, model())\n",
    "    \n",
    "    if max_models is not None:\n",
    "        random_search = RandomizedSearchCV(pipe, param_grid, scoring=scoring_function,\n",
    "                                   n_iter=max_models, verbose=0)\n",
    "    else:\n",
    "        random_search = GridSearchCV(pipe, param_grid, scoring=scoring_function,\n",
    "                                   n_iter=max_models, verbose=0)\n",
    "\n",
    "    random_search = random_search.fit(x_train, y_train)\n",
    "    best_params = { k.split('__')[1]:v for (k,v) in zip(list(random_search.best_params_.keys()), list(random_search.best_params_.values()))} \n",
    "    if model.__name__ == 'Lasso' or model.__name__ == 'Ridge' or model.__name__ == 'ElasticNet':\n",
    "        print(f'Scaling Final Pipe: {model.__name__}')\n",
    "        final_pipe = final_pipe = make_pipeline(preprocessor, StandardScaler(), model(**best_params))\n",
    "    else:\n",
    "        final_pipe = make_pipeline(preprocessor, model(**best_params))\n",
    "    \n",
    "    score = cross_val_score(final_pipe, x_train, y_train, cv=5, scoring=scoring_function).mean()\n",
    "    \n",
    "    return final_pipe, score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad97fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'xgbclassifier__n_estimators': [110, 120],\n",
    "    'xgbclassifier__max_depth':[5,6],\n",
    "    'xgbclassifier__max_leaves':[40, 30, 50],\n",
    "    'xgbclassifier__reg_alpha': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__reg_lambda': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__colsample_bytree': [i/10 for i in range(2, 5)],\n",
    "    'xgbclassifier__learning_rate': [i/100 for i in range(3,6)],\n",
    "    'xgbclassifier__gamma': [i/100 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "lasso_param_grid = {\n",
    "    'lasso__alpha':[0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "ridge_param_grid = {\n",
    "    'ridge__alpha':[0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "elastic_net_param_grid = {\n",
    "    'elasticnet__alpha': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'elasticnet__l1_ratio':[0.01, 0.05, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'kneighborsclassifier__weights' : ['uniform'],\n",
    "    'kneighborsclassifier__algorithm' : ['auto'],\n",
    "    'kneighborsclassifier__n_neighbors' : [5,10,15, 20, 25, 30],\n",
    "    'kneighborsclassifier__leaf_size': [10],\n",
    "    'kneighborsclassifier__p': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b36dd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a4acd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a078caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Survived'\n",
    "y_train = train_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c0ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'PassengerId'\n",
    "pred_col = f'Predicted_{label}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4940fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables, categorical_variables = data_manipulation.get_numerical_categorical_variables(train_df,\\\n",
    "                                                                                            test_df, id_column)                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f9175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c47175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_dist(df, variables):\n",
    "    for c in variables:\n",
    "        print(f'Variable: {c}')\n",
    "        display(df[c].describe())\n",
    "        plt.hist(df[c])\n",
    "        plt.title(f'Distribution for {c}')\n",
    "        plt.show()\n",
    "        \n",
    "def plot_discrete_variable_dist(df, variables):\n",
    "    for c in variables:\n",
    "        print(f'Variable: {c}')\n",
    "        display(df[c].value_counts(normalize=True))\n",
    "        plt.hist(df[c])\n",
    "        plt.title(f'Distribution for {c}')\n",
    "        plt.show()\n",
    "        \n",
    "def plot_cat_variable_dist(df, variables):\n",
    "    for c in variables:\n",
    "        print(f'Variable: {c}')\n",
    "        display(df[c].value_counts(normalize=True))\n",
    "        plt.bar(df[c].value_counts().index, df[c].value_counts())\n",
    "        plt.title(f'Distribution for {c}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c74f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_train, y_train, x_test, model, id_col_name, id_col, pred_col, label, filename):\n",
    "    model = model.fit(x_train, y_train)\n",
    "    test_pred = model.predict(x_test)\n",
    "    \n",
    "    x_test[pred_col] = test_pred\n",
    "    x_test[id_col_name] = id_col\n",
    "    \n",
    "    pred = x_test[[id_col_name, pred_col]]\n",
    "    columns = dict()\n",
    "    columns[pred_col] = label\n",
    "    pred = pred.rename(columns=columns)\n",
    "    pred.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781b0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>77.104377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>19.865320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.224467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column_name  percent_missing\n",
       "10        Cabin        77.104377\n",
       "5           Age        19.865320\n",
       "11     Embarked         0.224467\n",
       "0   PassengerId         0.000000\n",
       "1      Survived         0.000000\n",
       "2        Pclass         0.000000\n",
       "3          Name         0.000000\n",
       "4           Sex         0.000000\n",
       "6         SibSp         0.000000\n",
       "7         Parch         0.000000\n",
       "8        Ticket         0.000000\n",
       "9          Fare         0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_df = missing_values.get_variable_missing_values(train_df).reset_index(drop=True).sort_values('percent_missing', ascending=False)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb8bc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = train_df.copy()\n",
    "test_df2 = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e67f87cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PassengerId'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1e62b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessor(train_df, id_column, label):\n",
    "    numerical_imputer = SimpleImputer(strategy='mean')\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    categorical_variables, discrete_numerical_variables,\\\n",
    "    continuous_numerical_variables = data_manipulation.get_variables(train_df, [], id_column)\n",
    "    discrete_numerical_variables = list(set(discrete_numerical_variables) - set([label])) \n",
    "    ind_continuous_variables = list(set(continuous_numerical_variables) - set([label]))\n",
    "    numerical_variables = continuous_numerical_variables + discrete_numerical_variables\n",
    "\n",
    "    categorical_columns_selector = selector(dtype_exclude='number')\n",
    "    categorical_columns = categorical_columns_selector(train_df)\n",
    "    categorical_columns = list(set(categorical_columns) - set([label]))\n",
    "    #categorical_columns = ['Embarked', 'Ticket', 'Sex', 'Cabin']\n",
    "    ohe2 = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    categorical_pipeline2 = make_pipeline(categorical_imputer, ohe2)\n",
    "    \n",
    "    print(f'Continuous Variables: {ind_continuous_variables}')\n",
    "    print(f'Discrete Numerical Variables: {discrete_numerical_variables}')\n",
    "    print(f'Categorical Variables: {categorical_columns}')\n",
    "    \n",
    "    preprocessor = make_column_transformer((categorical_pipeline2, categorical_columns),\n",
    "                                           (numerical_imputer, ind_continuous_variables),\n",
    "                                           (categorical_imputer, discrete_numerical_variables),\n",
    "                                        )\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30e7d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stacking_classifier(train_df, y_train, estimators, final_estimator, scoring_function):\n",
    "    stacking_classifier = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=final_estimator,\n",
    "        )\n",
    "    \n",
    "    score = cross_val_score(stacking_classifier, train_df, y_train, cv=5, scoring=scoring_function).mean()\n",
    "    print(f'Score: {score}')\n",
    "    return stacking_classifier, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65596172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(preprocessor, train_df, y_train, dt_param_grid, rf_param_grid, knn_param_grid, xgb_param_grid,\\\n",
    "                    gbr_param_grid):\n",
    "    \n",
    "    dt_final_pipe, dt_score, dt_best_params = get_pipeline_cross_val_score(preprocessor, DecisionTreeClassifier,\\\n",
    "                                            dt_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'DT Score: {dt_score}, dt best params: {dt_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    rf_final_pipe, rf_score, rf_best_params = get_pipeline_cross_val_score(preprocessor, RandomForestClassifier,\\\n",
    "                                                            rf_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'RF Score: {rf_score}, RF best params: {rf_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    knn_final_pipe, knn_score, knn_best_params = get_pipeline_cross_val_score(preprocessor, KNeighborsClassifier,\\\n",
    "                                                knn_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'KNN Score: {knn_score}, KNN best params: {knn_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    xgb_final_pipe, xgb_score, xgb_best_params = get_pipeline_cross_val_score(preprocessor, XGBClassifier, xgb_param_grid,\\\n",
    "                                                train_df, y_train, 'accuracy', 50)\n",
    "    print(f'XGB Score: {xgb_score}, XGB best params: {xgb_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    gbr_final_pipe, gbr_score, gbr_best_params = get_pipeline_cross_val_score(preprocessor, GradientBoostingClassifier,\\\n",
    "                                                gbr_param_grid, train_df, y_train, 'accuracy', 50)\n",
    "    print(f'GBR Score: {gbr_score}, GBR best params: {gbr_best_params}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    lr_final_pipe = make_pipeline(preprocessor, LogisticRegression())\n",
    "    lr_score = cross_val_score(lr_final_pipe, train_df, y_train, cv=5, scoring='accuracy').mean()\n",
    "    print(f'Logistic Regression Score: {lr_score}')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    return {'DecisionTree': dt_final_pipe, 'RandomForest': rf_final_pipe, 'KNN': knn_final_pipe, 'XGB': xgb_final_pipe,\\\n",
    "            'GBR': gbr_final_pipe, 'LogisticRegression': lr_final_pipe }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcce4f2",
   "metadata": {},
   "source": [
    "Code to train stack classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ed0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_param_grid = {\n",
    "    'decisiontreeclassifier__max_depth':[2,3],\n",
    "    'decisiontreeclassifier__min_samples_split':[10, 20, 30],\n",
    "    'decisiontreeclassifier__min_samples_leaf':[10, 20, 30],\n",
    "    'decisiontreeclassifier__max_features' : ['sqrt'],\n",
    "    'decisiontreeclassifier__min_impurity_decrease': [i/100 for i in range(1, 3)],\n",
    "    'decisiontreeclassifier__ccp_alpha': [i/10 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators':[100, 500, 1000],\n",
    "    'randomforestclassifier__min_samples_split':[10, 20, 30, 40, 50],\n",
    "    'randomforestclassifier__max_depth': [2,3,4,5],\n",
    "    'randomforestclassifier__min_samples_leaf': [5, 10, 15, 20, 25, 30],\n",
    "    'randomforestclassifier__min_impurity_decrease': [0.002, 0.004, 0.006, 0.008]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'kneighborsclassifier__weights' : ['uniform'],\n",
    "    'kneighborsclassifier__algorithm' : ['auto'],\n",
    "    'kneighborsclassifier__n_neighbors' : [5,10,15, 20, 25, 30],\n",
    "    'kneighborsclassifier__leaf_size': [10],\n",
    "    'kneighborsclassifier__p': [1],\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'xgbclassifier__n_estimators': [110, 120],\n",
    "    'xgbclassifier__max_depth':[5,6],\n",
    "    'xgbclassifier__max_leaves':[40, 30, 50],\n",
    "    'xgbclassifier__reg_alpha': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__reg_lambda': [i/100 for i in range(1,3)],\n",
    "    'xgbclassifier__colsample_bytree': [i/10 for i in range(2, 5)],\n",
    "    'xgbclassifier__learning_rate': [i/100 for i in range(3,6)],\n",
    "    'xgbclassifier__gamma': [i/100 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "gbr_param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [1000, 1200],\n",
    "    'gradientboostingclassifier__max_depth':[4,5,6],\n",
    "    'gradientboostingclassifier__max_leaf_nodes':[40, 30, 50],\n",
    "    'gradientboostingclassifier__min_samples_split':[40, 30, 50],\n",
    "    'gradientboostingclassifier__subsample': [i/10 for i in range(2, 5)],\n",
    "    'gradientboostingclassifier__learning_rate': [i/100 for i in range(3,6)],\n",
    "    'gradientboostingclassifier__max_features': [i/100 for i in range(1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b183c",
   "metadata": {},
   "source": [
    "#### Base KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a35a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(train_df3, y_train, test_df3, knn_final_pipe, id_column, pred_col, label, 'knn_clf_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0952660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(worksheet, row_index):\n",
    "    num_rows = worksheet.max_row\n",
    "    num_cols = worksheet.max_column\n",
    "    headers = []\n",
    "    for i in range(row_index, row_index + 1):\n",
    "        for j in range(1, num_cols + 1):\n",
    "            cell = worksheet.cell(row=i, column=j)\n",
    "            if cell.value:\n",
    "                #print(f'Cell at ({i}, {j}): {cell.value}')\n",
    "                headers.append(cell.value)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56ba45",
   "metadata": {},
   "source": [
    "change it to use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf0fbdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(workbook, worksheet_name, data, row_index, workbook_title):\n",
    "    worksheet = workbook[worksheet_name]\n",
    "    current_row = worksheet.max_row + 1\n",
    "    headers = get_headers(worksheet, row_index)\n",
    "    num_cols = len(headers)\n",
    "    print(f'Num columns: {num_cols}')\n",
    "    print(f'current row: {current_row}')\n",
    "    cell = worksheet.cell(row=current_row - 1, column=1)\n",
    "    prev_version = 0\n",
    "    if cell.value != 'Version':\n",
    "        current_version = cell.value + 1\n",
    "        current_cell = worksheet.cell(row=current_row, column=1)\n",
    "        current_cell.value = current_version\n",
    "    else:\n",
    "        current_cell = worksheet.cell(row=current_row, column=1)\n",
    "        current_cell.value = 1\n",
    "        \n",
    "    for j in range(2, num_cols + 1):\n",
    "        cell = worksheet.cell(row=current_row, column=j)\n",
    "        cell.value = str(list(data.values())[j - 3])\n",
    "        print(f'Current Row = {current_row}, current column: {j}, cell_value: {cell.value}')\n",
    "    workbook.save(workbook_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17ed374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(preprocessor, model, hyper_parameter_set, train_df, y_train, scoring_function, max_models,\\\n",
    "                         workbook, worksheet_name, workbook_name):\n",
    "    \n",
    "    final_pipe, train_score, best_params = get_pipeline_cross_val_score(preprocessor, model,\\\n",
    "                                            hyper_parameter_set, train_df, y_train, scoring_function, max_models)\n",
    "    \n",
    "    data = dict()\n",
    "    feature_list = list(train_df.columns)\n",
    "    feature_str = ',\\n '.join(feature_list)\n",
    "    \n",
    "    print(f'train_score: {train_score}')\n",
    "    \n",
    "    #workbook_name = 'Titanic Survival Model.xlsx'\n",
    "    sheet = pd.read_excel(workbook_name, sheet_name=worksheet_name).rename(columns=lambda x: x.strip())\n",
    "    \n",
    "    if len(sheet) > 0:\n",
    "        old_version = sheet.loc[len(sheet) - 1, 'Version']\n",
    "        new_version = old_version + 1\n",
    "    else:\n",
    "        new_version = 1\n",
    "        \n",
    "    public_score = 0\n",
    "    sheet.loc[len(sheet)] = [new_version, feature_str, hyper_parameter_set, best_params, train_score, public_score] # row\n",
    "\n",
    "    with pd.ExcelWriter(workbook_name,\n",
    "                        mode='a', if_sheet_exists='replace') as writer:  \n",
    "        sheet.to_excel(writer, sheet_name=worksheet_name, index=False)\n",
    "    #row_index = 1\n",
    "    #save_results(workbook, worksheet_name, data, row_index, workbook_name)\n",
    "    \n",
    "    return final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7451bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd4b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = load_workbook('Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de077589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"worksheet = workbook['KNN']\\ncurrent_row = worksheet.max_row + 1\\nrow_index = 1\\nheaders = get_headers(worksheet, row_index)\\nnum_cols = len(headers)\\nprint(f'Num columns: {num_cols}')\\n\\ncell = worksheet.cell(row=current_row, column=1)\\nif cell.value:\\n    prev_version = cell.value\\nelse:\\n    prev_version = 1\\nprint(f'cell value: {cell.value}')\\n#if worksheet.cell(row=current_row - 1, column=1).value\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"worksheet = workbook['KNN']\n",
    "current_row = worksheet.max_row + 1\n",
    "row_index = 1\n",
    "headers = get_headers(worksheet, row_index)\n",
    "num_cols = len(headers)\n",
    "print(f'Num columns: {num_cols}')\n",
    "\n",
    "cell = worksheet.cell(row=current_row, column=1)\n",
    "if cell.value:\n",
    "    prev_version = cell.value\n",
    "else:\n",
    "    prev_version = 1\n",
    "print(f'cell value: {cell.value}')\n",
    "#if worksheet.cell(row=current_row - 1, column=1).value\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1e31503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(obj, query=''):\n",
    "    for field in dir(obj):\n",
    "        if field[0:2] != '__' and field[0] != '_':\n",
    "            if query.lower() in field.lower():\n",
    "                print(f'Field: {field}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9325f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_columns(train_df, label):\n",
    "    categorical_columns_selector = selector(dtype_exclude='number')\n",
    "    categorical_columns = categorical_columns_selector(train_df)\n",
    "    categorical_columns = list(set(categorical_columns) - set([label]))\n",
    "    \n",
    "    return categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ebd1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_variables(train_df, id_column, label):\n",
    "    categorical_variables, discrete_numerical_variables,\\\n",
    "    continuous_numerical_variables = data_manipulation.get_variables(train_df, [], id_column)\n",
    "    discrete_numerical_variables = list(set(discrete_numerical_variables) - set([label])) \n",
    "    ind_continuous_variables = list(set(continuous_numerical_variables) - set([label]))\n",
    "    \n",
    "    return ind_continuous_variables, discrete_numerical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e35a85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_continuous_variables, discrete_numerical_variables = get_numerical_variables(train_df2, id_column, label)\n",
    "categorical_columns = get_categorical_columns(train_df2, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08aa3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = categorical_columns + ind_continuous_variables + discrete_numerical_variables\n",
    "train_df3 = train_df2[variables]\n",
    "test_df3 = test_df2[variables]\n",
    "test_df3[id_column] = test_df2[id_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe0218de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Age', 'Fare']\n",
      "Discrete Numerical Variables: ['Pclass', 'Parch', 'SibSp']\n",
      "Categorical Variables: ['Cabin', 'Sex', 'Embarked', 'Name', 'Ticket']\n"
     ]
    }
   ],
   "source": [
    "preprocessor = get_preprocessor(train_df3, id_column, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc3505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "train_score: 0.6161634548992531\n",
      "CPU times: total: 5.16 s\n",
      "Wall time: 6.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_final_pipe = train_classifier(preprocessor, DecisionTreeClassifier, dt_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'DecisionTree', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06a8b790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hyperparameter Set</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Public Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Version, Features, Hyperparameter Set, Best Values, Accuracy, Public Accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workbook_name = 'Titanic Survival Model.xlsx'\n",
    "sheet = pd.read_excel(workbook_name, sheet_name='DecisionTree').rename(columns=lambda x: x.strip())\n",
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1348a6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4573c98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Version', 'Features', 'Hyperparameter Set', 'Best Values', 'Accuracy',\n",
       "       'Public Accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "267b79d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hyperparameter Set</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Public Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tepig</td>\n",
       "      <td>a</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version Features Hyperparameter Set  Best Values  Accuracy  Public Accuracy\n",
       "0        1    tepig                  a          0.9       0.8              0.7"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05dc8c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35f49bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cabin,\\n Embarked,\\n Ticket,\\n Sex,\\n Name,\\n Age,\\n Fare,\\n Pclass,\\n Parch,\\n SibSp'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = list(train_df3.columns)\n",
    "feature_str = ',\\n '.join(feature_list)\n",
    "feature_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62acb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook_name = 'Titanic Survival Model.xlsx'\n",
    "sheet = pd.read_excel(workbook_name, sheet_name='DecisionTree').rename(columns=lambda x: x.strip())\n",
    "\n",
    "old_version = sheet.loc[len(sheet) - 1, 'Version']\n",
    "sheet.loc[len(sheet)] = [old_version + 1, feature_str, 'a', 0.91, 0.81, 0] # row\n",
    "\n",
    "with pd.ExcelWriter('Titanic Survival Model.xlsx',\n",
    "                    mode='a', if_sheet_exists='replace') as writer:  \n",
    "    sheet.to_excel(writer, sheet_name='DecisionTree', index=False)\n",
    "\n",
    "#how to append rows to excel spreadsheet\n",
    "#sheet.to_excel(workbook_name, sheet_name='DecisionTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0ea7295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dt_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e7bc950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hyperparameter Set</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Public Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tepig</td>\n",
       "      <td>a</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cabin,\\n Embarked,\\n Ticket,\\n Sex,\\n Name,\\n ...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cabin,\\n Embarked,\\n Ticket,\\n Sex,\\n Name,\\n ...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version                                           Features  \\\n",
       "0        1                                              tepig   \n",
       "1        2  Cabin,\\n Embarked,\\n Ticket,\\n Sex,\\n Name,\\n ...   \n",
       "2        3  Cabin,\\n Embarked,\\n Ticket,\\n Sex,\\n Name,\\n ...   \n",
       "\n",
       "  Hyperparameter Set  Best Values  Accuracy  Public Accuracy  \n",
       "0                  a         0.90      0.80             0.70  \n",
       "1                  a         0.91      0.81             0.71  \n",
       "2                  a         0.91      0.81             0.00  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a89b6469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.io.excel._openpyxl.OpenpyxlWriter"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a918536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hyperparameter Set</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Public Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tepig</td>\n",
       "      <td>a</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version  Features Hyperparameter Set  Best Values  Accuracy  \\\n",
       "0         1    tepig                  a          0.9       0.8   \n",
       "\n",
       "   Public Accuracy  \n",
       "0              0.7  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c34d1ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hyperparameter Set</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Public Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tepig</td>\n",
       "      <td>a</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version  Features Hyperparameter Set  Best Values  Accuracy  \\\n",
       "0         1    tepig                  a          0.9       0.8   \n",
       "\n",
       "   Public Accuracy  \n",
       "0              0.7  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('Titanic Survival Model.xlsx', sheet_name='DecisionTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "500b3703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic Regression',\n",
       " 'KNN',\n",
       " 'XGBClassifier',\n",
       " 'GBRClassifier',\n",
       " 'RandomForest',\n",
       " 'DecisionTree',\n",
       " 'Sheet1',\n",
       " 'Stacked',\n",
       " 'Voting']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.ExcelFile('Titanic Survival Model.xlsx').sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73ffd832",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'DecisionTree' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitanic Survival Model.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecisionTree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Data_Science_Projects\\python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:517\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 517\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32m~\\Data_Science_Projects\\python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1629\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1591\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1610\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Data_Science_Projects\\python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:788\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 788\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n",
      "File \u001b[1;32m~\\Data_Science_Projects\\python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:583\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook[name]\n",
      "File \u001b[1;32m~\\Data_Science_Projects\\python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:639\u001b[0m, in \u001b[0;36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheet_names:\n\u001b[1;32m--> 639\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorksheet named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Worksheet named 'DecisionTree' not found"
     ]
    }
   ],
   "source": [
    "pd.read_excel('Titanic Survival Model.xlsx').sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9465c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "RF SCORE: 0.6161634548992531\n",
      "Num columns: 5\n",
      "Current Row = 7, current column: 2, cell_value: {'randomforestclassifier__n_estimators': [100, 500, 1000], 'randomforestclassifier__min_samples_split': [10, 20, 30, 40, 50], 'randomforestclassifier__max_depth': [2, 3, 4, 5], 'randomforestclassifier__min_samples_leaf': [5, 10, 15, 20, 25, 30], 'randomforestclassifier__min_impurity_decrease': [0.002, 0.004, 0.006, 0.008]}\n",
      "Current Row = 7, current column: 3, cell_value: {'n_estimators': 1000, 'min_samples_split': 30, 'min_samples_leaf': 10, 'min_impurity_decrease': 0.002, 'max_depth': 4}\n",
      "Current Row = 7, current column: 4, cell_value: 0.6161634548992531\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_rf_classifier(preprocessor, RandomForestClassifier, rf_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'RandomForest', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f961ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 6, current column: 2, cell_value: {'gradientboostingclassifier__n_estimators': [1000, 1200], 'gradientboostingclassifier__max_depth': [4, 5, 6], 'gradientboostingclassifier__max_leaf_nodes': [40, 30, 50], 'gradientboostingclassifier__min_samples_split': [40, 30, 50], 'gradientboostingclassifier__subsample': [0.2, 0.3, 0.4], 'gradientboostingclassifier__learning_rate': [0.03, 0.04, 0.05], 'gradientboostingclassifier__max_features': [0.01, 0.02]}\n",
      "Current Row = 6, current column: 3, cell_value: {'subsample': 0.2, 'n_estimators': 1000, 'min_samples_split': 40, 'max_leaf_nodes': 50, 'max_features': 0.02, 'max_depth': 5, 'learning_rate': 0.05}\n",
      "Current Row = 6, current column: 4, cell_value: 0.8249011361496453\n",
      "CPU times: total: 2min 33s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_gbr_classifier(preprocessor, GradientBoostingClassifier, gbr_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'GBRClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "871718ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 6, current column: 2, cell_value: {'kneighborsclassifier__weights': ['uniform'], 'kneighborsclassifier__algorithm': ['auto'], 'kneighborsclassifier__n_neighbors': [5, 10, 15, 20, 25, 30], 'kneighborsclassifier__leaf_size': [10], 'kneighborsclassifier__p': [1]}\n",
      "Current Row = 6, current column: 3, cell_value: {'weights': 'uniform', 'p': 1, 'n_neighbors': 5, 'leaf_size': 10, 'algorithm': 'auto'}\n",
      "Current Row = 6, current column: 4, cell_value: 0.744121524072563\n",
      "CPU times: total: 5.27 s\n",
      "Wall time: 7.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_knn_classifier(preprocessor, KNeighborsClassifier, knn_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'KNN', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b54a73a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 6, current column: 2, cell_value: {'xgbclassifier__n_estimators': [110, 120], 'xgbclassifier__max_depth': [5, 6], 'xgbclassifier__max_leaves': [40, 30, 50], 'xgbclassifier__reg_alpha': [0.01, 0.02], 'xgbclassifier__reg_lambda': [0.01, 0.02], 'xgbclassifier__colsample_bytree': [0.2, 0.3, 0.4], 'xgbclassifier__learning_rate': [0.03, 0.04, 0.05], 'xgbclassifier__gamma': [0.01, 0.02]}\n",
      "Current Row = 6, current column: 3, cell_value: {'reg_lambda': 0.02, 'reg_alpha': 0.01, 'n_estimators': 110, 'max_leaves': 50, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.02, 'colsample_bytree': 0.4}\n",
      "Current Row = 6, current column: 4, cell_value: 0.8395329860021341\n",
      "CPU times: total: 8min 1s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_xgb_classifier(preprocessor, XGBClassifier, xgb_param_grid, train_df3, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'XGBClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78f8afe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Training on Source Dataset without name column</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Version</td>\n",
       "      <td>Hyperparameter Set</td>\n",
       "      <td>Best Values</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Public Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>knn_param_grid = {\\n    'kneighborsclassifier_...</td>\n",
       "      <td>{'weights': 'uniform',\\n  'p': 1,\\n  'n_neighb...</td>\n",
       "      <td>0.746369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>knn_param_grid = {\\n    'kneighborsclassifier_...</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.746369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'kneighborsclassifier__weights': ['uniform'],...</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.744121524072563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Training on Source Dataset without name column  \\\n",
       "0                                           Version      \n",
       "1                                                  1     \n",
       "2                                                  2     \n",
       "3                                                  3     \n",
       "\n",
       "                                          Unnamed: 1  \\\n",
       "0                                 Hyperparameter Set   \n",
       "1  knn_param_grid = {\\n    'kneighborsclassifier_...   \n",
       "2  knn_param_grid = {\\n    'kneighborsclassifier_...   \n",
       "3  {'kneighborsclassifier__weights': ['uniform'],...   \n",
       "\n",
       "                                          Unnamed: 2         Unnamed: 3  \\\n",
       "0                                        Best Values           Accuracy   \n",
       "1  {'weights': 'uniform',\\n  'p': 1,\\n  'n_neighb...           0.746369   \n",
       "2  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.746369   \n",
       "3  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...  0.744121524072563   \n",
       "\n",
       "        Unnamed: 4  \n",
       "0  Public Accuracy  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Titanic Survival Model.xlsx', sheet_name='KNN')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eabeec49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Training on Source Dataset without name column</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Version</td>\n",
       "      <td>Hyperparameter Set</td>\n",
       "      <td>Best Values</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Public Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gbr_param_grid = {\\n    'gradientboostingclass...</td>\n",
       "      <td>{'subsample': 0.4,\\n  'n_estimators': 1200,\\n...</td>\n",
       "      <td>0.837267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gbr_param_grid = {\\n    'gradientboostingclass...</td>\n",
       "      <td>{'subsample': 0.4,\\n 'n_estimators': 1200,\\n '...</td>\n",
       "      <td>0.839508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'gradientboostingclassifier__n_estimators': [...</td>\n",
       "      <td>{'subsample': 0.4, 'n_estimators': 1000, 'min_...</td>\n",
       "      <td>0.8439771514656957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Training on Source Dataset without name column  \\\n",
       "0                                           Version      \n",
       "1                                                  1     \n",
       "2                                                  2     \n",
       "3                                                  3     \n",
       "\n",
       "                                          Unnamed: 1  \\\n",
       "0                                 Hyperparameter Set   \n",
       "1  gbr_param_grid = {\\n    'gradientboostingclass...   \n",
       "2  gbr_param_grid = {\\n    'gradientboostingclass...   \n",
       "3  {'gradientboostingclassifier__n_estimators': [...   \n",
       "\n",
       "                                          Unnamed: 2          Unnamed: 3  \\\n",
       "0                                        Best Values            Accuracy   \n",
       "1   {'subsample': 0.4,\\n  'n_estimators': 1200,\\n...            0.837267   \n",
       "2  {'subsample': 0.4,\\n 'n_estimators': 1200,\\n '...            0.839508   \n",
       "3  {'subsample': 0.4, 'n_estimators': 1000, 'min_...  0.8439771514656957   \n",
       "\n",
       "        Unnamed: 4  \n",
       "0  Public Accuracy  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Titanic Survival Model.xlsx', sheet_name='GBRClassifier')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d0dd94bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Training on Source Dataset without name column</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Version</td>\n",
       "      <td>Hyperparameter Set</td>\n",
       "      <td>Best Values</td>\n",
       "      <td>Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rf_param_grid = {\\n    'randomforestclassifier...</td>\n",
       "      <td>{'n_estimators': 1000,\\n  'min_samples_split':...</td>\n",
       "      <td>0.6161634548992531,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rf_param_grid = {\\n    'randomforestclassifier...</td>\n",
       "      <td>{'n_estimators': 100,\\n  'min_samples_split': ...</td>\n",
       "      <td>0.616163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rf_param_grid = {\\n    'randomforestclassifier...</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 50,...</td>\n",
       "      <td>0.616163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': [100,...</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 30,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Training on Source Dataset without name column  \\\n",
       "0                                           Version      \n",
       "1                                                  1     \n",
       "2                                                  2     \n",
       "3                                                  3     \n",
       "4                                                  4     \n",
       "\n",
       "                                          Unnamed: 1  \\\n",
       "0                                 Hyperparameter Set   \n",
       "1  rf_param_grid = {\\n    'randomforestclassifier...   \n",
       "2  rf_param_grid = {\\n    'randomforestclassifier...   \n",
       "3  rf_param_grid = {\\n    'randomforestclassifier...   \n",
       "4  {'randomforestclassifier__n_estimators': [100,...   \n",
       "\n",
       "                                          Unnamed: 2           Unnamed: 3  \n",
       "0                                        Best Values             Accuracy  \n",
       "1  {'n_estimators': 1000,\\n  'min_samples_split':...  0.6161634548992531,  \n",
       "2  {'n_estimators': 100,\\n  'min_samples_split': ...             0.616163  \n",
       "3  {'n_estimators': 100, 'min_samples_split': 50,...             0.616163  \n",
       "4  {'n_estimators': 100, 'min_samples_split': 30,...                  NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Titanic Survival Model.xlsx', sheet_name='RandomForest')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ce288",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b093e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_married(x):\n",
    "    return 1 if 'mrs.' in x['Name'].lower() and x['Sex'] == 'female' else 0\n",
    "\n",
    "def get_title(x):\n",
    "    return x.split(', ')[1].split(' ')[0]\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def convert_title(title):\n",
    "    if title not in ['Mr.', 'Miss.', 'Mrs.', 'Master']:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e91955ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4 = pd.read_csv('train.csv')\n",
    "test_df4 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39e4ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4['is_married'] = train_df4.apply(lambda x: is_married(x), axis='columns')\n",
    "train_df4['title'] = train_df4['Name'].apply(lambda x: get_title(x))\n",
    "train_df4['title_converted'] = train_df4['title'].apply(lambda x: convert_title(x))\n",
    "train_df4['sex_converted'] = train_df4['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "train_df4['age_group'] = train_df4['Age'].apply(lambda x: get_age_group(x))\n",
    "train_df4['family_size'] = train_df4['Parch'] + train_df4['SibSp']\n",
    "train_df4['solo_traveler'] = train_df4['family_size'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f96090ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df4['is_married'] = test_df4.apply(lambda x: is_married(x), axis='columns')\n",
    "test_df4['title'] = test_df4['Name'].apply(lambda x: get_title(x))\n",
    "test_df4['title_converted'] = test_df4['title'].apply(lambda x: convert_title(x))\n",
    "test_df4['sex_converted'] = test_df4['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "test_df4['age_group'] = test_df4['Age'].apply(lambda x: get_age_group(x))\n",
    "test_df4['family_size'] = test_df4['Parch'] + test_df4['SibSp']\n",
    "test_df4['solo_traveler'] = test_df4['family_size'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aad475b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nec_variables = ['Pclass', 'Embarked', 'Fare','is_married', 'title_converted', 'sex_converted', 'age_group', 'Age', 'family_size', 'solo_traveler', 'Parch', 'SibSp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6597a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df5 = train_df4[nec_variables]\n",
    "test_df5 = test_df4[nec_variables]\n",
    "y_train = train_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b50dff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df5['is_married'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6eb95c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass               int64\n",
       "Embarked            object\n",
       "Fare               float64\n",
       "is_married           int64\n",
       "title_converted     object\n",
       "sex_converted        int64\n",
       "age_group            int64\n",
       "Age                float64\n",
       "family_size          int64\n",
       "solo_traveler        int64\n",
       "Parch                int64\n",
       "SibSp                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df5.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c41dd0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Fare', 'Age']\n",
      "Discrete Numerical Variables: ['is_married', 'solo_traveler', 'sex_converted', 'family_size', 'SibSp', 'age_group', 'Pclass', 'Parch']\n",
      "Categorical Variables: ['Embarked', 'title_converted']\n"
     ]
    }
   ],
   "source": [
    "preprocessor2 = get_preprocessor(train_df5, id_column, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b07efb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(['Fare', 'Age'] + ['is_married', 'solo_traveler', 'sex_converted', 'family_size', 'SibSp', 'age_group', 'Pclass', 'Parch'] + ['Embarked', 'title_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc66405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "DT score: 0.7150398593936351\n",
      "Num columns: 5\n",
      "Current Row = 9, current column: 2, cell_value: {'decisiontreeclassifier__max_depth': [2, 3], 'decisiontreeclassifier__min_samples_split': [10, 20, 30], 'decisiontreeclassifier__min_samples_leaf': [10, 20, 30], 'decisiontreeclassifier__max_features': ['sqrt'], 'decisiontreeclassifier__min_impurity_decrease': [0.01, 0.02], 'decisiontreeclassifier__ccp_alpha': [0.1, 0.2]}\n",
      "Current Row = 9, current column: 3, cell_value: {'min_samples_split': 20, 'min_samples_leaf': 20, 'min_impurity_decrease': 0.02, 'max_features': 'sqrt', 'max_depth': 2, 'ccp_alpha': 0.1}\n",
      "Current Row = 9, current column: 4, cell_value: 0.7150398593936351\n",
      "CPU times: total: 2.58 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_final_pipe = train_dt_classifier(preprocessor2, DecisionTreeClassifier, dt_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'DecisionTree', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "292a99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "RF SCORE: 0.8159186491745652\n",
      "Num columns: 5\n",
      "Current Row = 9, current column: 2, cell_value: {'randomforestclassifier__n_estimators': [100, 500, 1000], 'randomforestclassifier__min_samples_split': [10, 20, 30, 40, 50], 'randomforestclassifier__max_depth': [2, 3, 4, 5], 'randomforestclassifier__min_samples_leaf': [5, 10, 15, 20, 25, 30], 'randomforestclassifier__min_impurity_decrease': [0.002, 0.004, 0.006, 0.008]}\n",
      "Current Row = 9, current column: 3, cell_value: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_impurity_decrease': 0.004, 'max_depth': 4}\n",
      "Current Row = 9, current column: 4, cell_value: 0.8159186491745652\n",
      "CPU times: total: 1min 23s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_final_pipe = train_rf_classifier(preprocessor2, RandomForestClassifier, rf_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'RandomForest', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98d8f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 10, current column: 2, cell_value: {'kneighborsclassifier__weights': ['uniform'], 'kneighborsclassifier__algorithm': ['auto'], 'kneighborsclassifier__n_neighbors': [5, 10, 15, 20, 25, 30], 'kneighborsclassifier__leaf_size': [10], 'kneighborsclassifier__p': [1]}\n",
      "Current Row = 10, current column: 3, cell_value: {'weights': 'uniform', 'p': 1, 'n_neighbors': 5, 'leaf_size': 10, 'algorithm': 'auto'}\n",
      "Current Row = 10, current column: 4, cell_value: 0.7508819283158622\n",
      "CPU times: total: 438 ms\n",
      "Wall time: 631 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_final_pipe = train_knn_classifier(preprocessor2, KNeighborsClassifier, knn_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'KNN', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9027355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 8, current column: 2, cell_value: {'xgbclassifier__n_estimators': [110, 120], 'xgbclassifier__max_depth': [5, 6], 'xgbclassifier__max_leaves': [40, 30, 50], 'xgbclassifier__reg_alpha': [0.01, 0.02], 'xgbclassifier__reg_lambda': [0.01, 0.02], 'xgbclassifier__colsample_bytree': [0.2, 0.3, 0.4], 'xgbclassifier__learning_rate': [0.03, 0.04, 0.05], 'xgbclassifier__gamma': [0.01, 0.02]}\n",
      "Current Row = 8, current column: 3, cell_value: {'reg_lambda': 0.01, 'reg_alpha': 0.01, 'n_estimators': 120, 'max_leaves': 30, 'max_depth': 6, 'learning_rate': 0.04, 'gamma': 0.02, 'colsample_bytree': 0.3}\n",
      "Current Row = 8, current column: 4, cell_value: 0.8395204318624068\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_final_pipe = train_xgb_classifier(preprocessor2, XGBClassifier, xgb_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'XGBClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1e2e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 8, current column: 2, cell_value: {'gradientboostingclassifier__n_estimators': [1000, 1200], 'gradientboostingclassifier__max_depth': [4, 5, 6], 'gradientboostingclassifier__max_leaf_nodes': [40, 30, 50], 'gradientboostingclassifier__min_samples_split': [40, 30, 50], 'gradientboostingclassifier__subsample': [0.2, 0.3, 0.4], 'gradientboostingclassifier__learning_rate': [0.03, 0.04, 0.05], 'gradientboostingclassifier__max_features': [0.01, 0.02]}\n",
      "Current Row = 8, current column: 3, cell_value: {'subsample': 0.3, 'n_estimators': 1000, 'min_samples_split': 40, 'max_leaf_nodes': 40, 'max_features': 0.02, 'max_depth': 5, 'learning_rate': 0.04}\n",
      "Current Row = 8, current column: 4, cell_value: 0.8237963718536188\n",
      "CPU times: total: 2min 8s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbr_final_pipe = train_gbr_classifier(preprocessor2, GradientBoostingClassifier, gbr_param_grid, train_df5, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'GBRClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f3db717",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final_pipe = make_pipeline(preprocessor2, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6554fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    " estimators = [\n",
    "        ('LogisticRegression', lr_final_pipe),\n",
    "         ('KNN', knn_final_pipe),\n",
    "        ('RandomForest', rf_final_pipe),\n",
    "        ('GradientBoostingClassifier', gbr_final_pipe),\n",
    "        ('XGBClassifier', xgb_final_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29882522",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_estimator = RandomForestClassifier()\n",
    "xgb_final_estimator = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "470807b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8136902893729208\n"
     ]
    }
   ],
   "source": [
    "rf_stack, rf_stack_score = train_stacking_classifier(train_df5, y_train, estimators, rf_final_estimator, 'accuracy')\n",
    "#predict(train_df5, y_train, test_df5, rf_stack, id_column,test_df[id_column], pred_col, label, 'rf_stack_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90538fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7789529847467203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7789529847467203"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_stack, xgb_stack_score = train_stacking_classifier(train_df5, y_train, estimators, xgb_final_estimator, 'accuracy')\n",
    "xgb_stack_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65a42535",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, xgb_stack, id_column, test_df[id_column], pred_col, label, 'xgb_stack_feat_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2ca82",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2403d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier with RF score: 0.8316489862532169\n"
     ]
    }
   ],
   "source": [
    "vote_rf = VotingClassifier(estimators=[('LogisticRegression', lr_final_pipe),\\\n",
    "                                         ('KNN', knn_final_pipe),\n",
    "                                         ('RF', rf_final_pipe),\n",
    "                                        ('GBR', gbr_final_pipe),\n",
    "                                        ('XGB', xgb_final_pipe)], voting='hard')\n",
    "\n",
    "score = cross_val_score(vote_rf, train_df5, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f'Voting Classifier with RF score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d0725cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, vote_rf, id_column, test_df[id_column], pred_col, label, 'vote_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec00b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    " estimators_no_rf = [\n",
    "        ('LogisticRegression', lr_final_pipe),\n",
    "         ('KNN', knn_final_pipe),\n",
    "        ('GradientBoostingClassifier', gbr_final_pipe),\n",
    "        ('XGBClassifier', xgb_final_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f32c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8069675475488042\n"
     ]
    }
   ],
   "source": [
    "rf_stack_no_rf, rf_stack_score = train_stacking_classifier(train_df5, y_train, estimators_no_rf, rf_final_estimator, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87e055a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7710878162073944\n"
     ]
    }
   ],
   "source": [
    "xgb_stack_no_rf, xgb_stack_score = train_stacking_classifier(train_df5, y_train, estimators_no_rf, xgb_final_estimator, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e28f267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, rf_stack_no_rf, id_column,test_df[id_column], pred_col, label, 'rf_stack_no_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8763d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, xgb_stack_no_rf, id_column,test_df[id_column], pred_col, label, 'xgb_stack_no_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1da39489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier with no RF score: 0.8294080723118448\n"
     ]
    }
   ],
   "source": [
    "vote_no_rf = VotingClassifier(estimators=[('LogisticRegression', lr_final_pipe),\\\n",
    "                                         ('KNN', knn_final_pipe),\n",
    "                                        ('GBR', gbr_final_pipe),\n",
    "                                        ('XGB', xgb_final_pipe)], voting='hard')\n",
    "\n",
    "score = cross_val_score(vote_no_rf, train_df5, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f'Voting Classifier with no RF score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00ad2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df5, y_train, test_df5, vote_no_rf, id_column, test_df[id_column], pred_col, label, 'vote_no_rf_feat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "57f778e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Embarked',\n",
       " 'Fare',\n",
       " 'is_married',\n",
       " 'title_converted',\n",
       " 'sex_converted',\n",
       " 'age_group',\n",
       " 'Age',\n",
       " 'family_size',\n",
       " 'solo_traveler',\n",
       " 'Parch',\n",
       " 'SibSp']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nec_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30018ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "14b6241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df6 = train_df4[nec_variables + ['Name', 'Ticket', 'Cabin']]\n",
    "test_df6 = test_df4[nec_variables + ['Name', 'Ticket', 'Cabin']]\n",
    "y_train = train_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f75d1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Fare', 'Age']\n",
      "Discrete Numerical Variables: ['is_married', 'solo_traveler', 'sex_converted', 'family_size', 'SibSp', 'age_group', 'Pclass', 'Parch']\n",
      "Categorical Variables: ['Embarked', 'title_converted', 'Ticket', 'Name', 'Cabin']\n"
     ]
    }
   ],
   "source": [
    "preprocessor3 = get_preprocessor(train_df6, id_column, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1e932ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Embarked,\\n title_converted,\\n Ticket,\\n Name,\\n Cabin'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['Embarked', 'title_converted', 'Ticket', 'Name', 'Cabin']\n",
    "',\\n '.join(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a1ce4",
   "metadata": {},
   "source": [
    "#### Using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b14994b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max models: 50\n",
      "DT score: 0.6161634548992531\n",
      "Num columns: 5\n",
      "Current Row = 10, current column: 2, cell_value: {'decisiontreeclassifier__max_depth': [2, 3], 'decisiontreeclassifier__min_samples_split': [10, 20, 30], 'decisiontreeclassifier__min_samples_leaf': [10, 20, 30], 'decisiontreeclassifier__max_features': ['sqrt'], 'decisiontreeclassifier__min_impurity_decrease': [0.01, 0.02], 'decisiontreeclassifier__ccp_alpha': [0.1, 0.2]}\n",
      "Current Row = 10, current column: 3, cell_value: {'min_samples_split': 20, 'min_samples_leaf': 30, 'min_impurity_decrease': 0.02, 'max_features': 'sqrt', 'max_depth': 2, 'ccp_alpha': 0.1}\n",
      "Current Row = 10, current column: 4, cell_value: 0.6161634548992531\n",
      "Max models: 50\n",
      "RF SCORE: 0.6161634548992531\n",
      "Num columns: 5\n",
      "Current Row = 10, current column: 2, cell_value: {'randomforestclassifier__n_estimators': [100, 500, 1000], 'randomforestclassifier__min_samples_split': [10, 20, 30, 40, 50], 'randomforestclassifier__max_depth': [2, 3, 4, 5], 'randomforestclassifier__min_samples_leaf': [5, 10, 15, 20, 25, 30], 'randomforestclassifier__min_impurity_decrease': [0.002, 0.004, 0.006, 0.008]}\n",
      "Current Row = 10, current column: 3, cell_value: {'n_estimators': 100, 'min_samples_split': 40, 'min_samples_leaf': 10, 'min_impurity_decrease': 0.004, 'max_depth': 5}\n",
      "Current Row = 10, current column: 4, cell_value: 0.6161634548992531\n",
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 11, current column: 2, cell_value: {'kneighborsclassifier__weights': ['uniform'], 'kneighborsclassifier__algorithm': ['auto'], 'kneighborsclassifier__n_neighbors': [5, 10, 15, 20, 25, 30], 'kneighborsclassifier__leaf_size': [10], 'kneighborsclassifier__p': [1]}\n",
      "Current Row = 11, current column: 3, cell_value: {'weights': 'uniform', 'p': 1, 'n_neighbors': 5, 'leaf_size': 10, 'algorithm': 'auto'}\n",
      "Current Row = 11, current column: 4, cell_value: 0.7531228422572342\n",
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 9, current column: 2, cell_value: {'xgbclassifier__n_estimators': [110, 120], 'xgbclassifier__max_depth': [5, 6], 'xgbclassifier__max_leaves': [40, 30, 50], 'xgbclassifier__reg_alpha': [0.01, 0.02], 'xgbclassifier__reg_lambda': [0.01, 0.02], 'xgbclassifier__colsample_bytree': [0.2, 0.3, 0.4], 'xgbclassifier__learning_rate': [0.03, 0.04, 0.05], 'xgbclassifier__gamma': [0.01, 0.02]}\n",
      "Current Row = 9, current column: 3, cell_value: {'reg_lambda': 0.01, 'reg_alpha': 0.01, 'n_estimators': 110, 'max_leaves': 40, 'max_depth': 6, 'learning_rate': 0.04, 'gamma': 0.02, 'colsample_bytree': 0.4}\n",
      "Current Row = 9, current column: 4, cell_value: 0.844002259745151\n",
      "Max models: 50\n",
      "Num columns: 5\n",
      "Current Row = 9, current column: 2, cell_value: {'gradientboostingclassifier__n_estimators': [1000, 1200], 'gradientboostingclassifier__max_depth': [4, 5, 6], 'gradientboostingclassifier__max_leaf_nodes': [40, 30, 50], 'gradientboostingclassifier__min_samples_split': [40, 30, 50], 'gradientboostingclassifier__subsample': [0.2, 0.3, 0.4], 'gradientboostingclassifier__learning_rate': [0.03, 0.04, 0.05], 'gradientboostingclassifier__max_features': [0.01, 0.02]}\n",
      "Current Row = 9, current column: 3, cell_value: {'subsample': 0.4, 'n_estimators': 1000, 'min_samples_split': 40, 'max_leaf_nodes': 50, 'max_features': 0.02, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Current Row = 9, current column: 4, cell_value: 0.8316427091833531\n",
      "CPU times: total: 13min 48s\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_final_pipe = train_dt_classifier(preprocessor3, DecisionTreeClassifier, dt_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'DecisionTree', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "rf_final_pipe = train_rf_classifier(preprocessor3, RandomForestClassifier, rf_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'RandomForest', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "knn_final_pipe = train_knn_classifier(preprocessor3, KNeighborsClassifier, knn_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'KNN', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "xgb_final_pipe = train_xgb_classifier(preprocessor3, XGBClassifier, xgb_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'XGBClassifier', 'Titanic Survival Model.xlsx')\n",
    "\n",
    "gbr_final_pipe = train_gbr_classifier(preprocessor3, GradientBoostingClassifier, gbr_param_grid, train_df6, y_train, 'accuracy', 50,\\\n",
    "                         workbook, 'GBRClassifier', 'Titanic Survival Model.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "61376621",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final_pipe = make_pipeline(preprocessor3, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d29a12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    " estimators = [\n",
    "        ('LogisticRegression', lr_final_pipe),\n",
    "         ('KNN', knn_final_pipe),\n",
    "        ('RandomForest', rf_final_pipe),\n",
    "        ('GradientBoostingClassifier', gbr_final_pipe),\n",
    "        ('XGBClassifier', xgb_final_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f7b4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_estimator = RandomForestClassifier()\n",
    "xgb_final_estimator = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9bf8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8114870378507314\n"
     ]
    }
   ],
   "source": [
    "rf_stack, rf_stack_score = train_stacking_classifier(train_df6, y_train, estimators, rf_final_estimator, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77915d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df6, y_train, test_df6, rf_stack, id_column, test_df[id_column], pred_col, label, 'rf_stack_feat_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e91e4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier with RF score: 0.8394827694432239\n"
     ]
    }
   ],
   "source": [
    "vote_rf = VotingClassifier(estimators=[('LogisticRegression', lr_final_pipe),\\\n",
    "                                         ('KNN', knn_final_pipe),\n",
    "                                           ('RF', rf_final_pipe),\n",
    "                                        ('GBR', gbr_final_pipe),\n",
    "                                        ('XGB', xgb_final_pipe)], voting='hard')\n",
    "\n",
    "score = cross_val_score(vote_rf, train_df6, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f'Voting Classifier with RF score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7baf530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(train_df6, y_train, test_df6, vote_rf, id_column, test_df[id_column], pred_col, label, 'vote_feat_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5edd4031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "60688e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Ticket'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "13e8a42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "13707cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450',\n",
       "       '330877', '17463', '349909', '347742', '237736', 'PP 9549',\n",
       "       '113783', 'A/5. 2151', '347082', '350406', '248706', '382652',\n",
       "       '244373', '345763', '2649', '239865', '248698', '330923', '113788',\n",
       "       '347077', '2631', '19950', '330959', '349216', 'PC 17601',\n",
       "       'PC 17569', '335677', 'C.A. 24579', 'PC 17604', '113789', '2677',\n",
       "       'A./5. 2152', '345764', '2651', '7546', '11668', '349253',\n",
       "       'SC/Paris 2123', '330958', 'S.C./A.4. 23567', '370371', '14311',\n",
       "       '2662', '349237', '3101295', 'A/4. 39886', 'PC 17572', '2926',\n",
       "       '113509', '19947', 'C.A. 31026', '2697', 'C.A. 34651', 'CA 2144',\n",
       "       '2669', '113572', '36973', '347088', 'PC 17605', '2661',\n",
       "       'C.A. 29395', 'S.P. 3464', '3101281', '315151', 'C.A. 33111',\n",
       "       'S.O.C. 14879', '2680', '1601', '348123', '349208', '374746',\n",
       "       '248738', '364516', '345767', '345779', '330932', '113059',\n",
       "       'SO/C 14885', '3101278', 'W./C. 6608', 'SOTON/OQ 392086', '343275',\n",
       "       '343276', '347466', 'W.E.P. 5734', 'C.A. 2315', '364500', '374910',\n",
       "       'PC 17754', 'PC 17759', '231919', '244367', '349245', '349215',\n",
       "       '35281', '7540', '3101276', '349207', '343120', '312991', '349249',\n",
       "       '371110', '110465', '2665', '324669', '4136', '2627',\n",
       "       'STON/O 2. 3101294', '370369', 'PC 17558', 'A4. 54510', '27267',\n",
       "       '370372', 'C 17369', '2668', '347061', '349241',\n",
       "       'SOTON/O.Q. 3101307', 'A/5. 3337', '228414', 'C.A. 29178',\n",
       "       'SC/PARIS 2133', '11752', '7534', 'PC 17593', '2678', '347081',\n",
       "       'STON/O2. 3101279', '365222', '231945', 'C.A. 33112', '350043',\n",
       "       '230080', '244310', 'S.O.P. 1166', '113776', 'A.5. 11206',\n",
       "       'A/5. 851', 'Fa 265302', 'PC 17597', '35851', 'SOTON/OQ 392090',\n",
       "       '315037', 'CA. 2343', '371362', 'C.A. 33595', '347068', '315093',\n",
       "       '363291', '113505', 'PC 17318', '111240', 'STON/O 2. 3101280',\n",
       "       '17764', '350404', '4133', 'PC 17595', '250653', 'LINE',\n",
       "       'SC/PARIS 2131', '230136', '315153', '113767', '370365', '111428',\n",
       "       '364849', '349247', '234604', '28424', '350046', 'PC 17610',\n",
       "       '368703', '4579', '370370', '248747', '345770', '3101264', '2628',\n",
       "       'A/5 3540', '347054', '2699', '367231', '112277',\n",
       "       'SOTON/O.Q. 3101311', 'F.C.C. 13528', 'A/5 21174', '250646',\n",
       "       '367229', '35273', 'STON/O2. 3101283', '243847', '11813',\n",
       "       'W/C 14208', 'SOTON/OQ 392089', '220367', '21440', '349234',\n",
       "       '19943', 'PP 4348', 'SW/PP 751', 'A/5 21173', '236171', '347067',\n",
       "       '237442', 'C.A. 29566', 'W./C. 6609', '26707', 'C.A. 31921',\n",
       "       '28665', 'SCO/W 1585', '367230', 'W./C. 14263',\n",
       "       'STON/O 2. 3101275', '2694', '19928', '347071', '250649', '11751',\n",
       "       '244252', '362316', '113514', 'A/5. 3336', '370129', '2650',\n",
       "       'PC 17585', '110152', 'PC 17755', '230433', '384461', '110413',\n",
       "       '112059', '382649', 'C.A. 17248', '347083', 'PC 17582', 'PC 17760',\n",
       "       '113798', '250644', 'PC 17596', '370375', '13502', '347073',\n",
       "       '239853', 'C.A. 2673', '336439', '347464', '345778', 'A/5. 10482',\n",
       "       '113056', '349239', '345774', '349206', '237798', '370373',\n",
       "       '19877', '11967', 'SC/Paris 2163', '349236', '349233', 'PC 17612',\n",
       "       '2693', '113781', '19988', '9234', '367226', '226593', 'A/5 2466',\n",
       "       '17421', 'PC 17758', 'P/PP 3381', 'PC 17485', '11767', 'PC 17608',\n",
       "       '250651', '349243', 'F.C.C. 13529', '347470', '29011', '36928',\n",
       "       '16966', 'A/5 21172', '349219', '234818', '345364', '28551',\n",
       "       '111361', '113043', 'PC 17611', '349225', '7598', '113784',\n",
       "       '248740', '244361', '229236', '248733', '31418', '386525',\n",
       "       'C.A. 37671', '315088', '7267', '113510', '2695', '2647', '345783',\n",
       "       '237671', '330931', '330980', 'SC/PARIS 2167', '2691',\n",
       "       'SOTON/O.Q. 3101310', 'C 7076', '110813', '2626', '14313',\n",
       "       'PC 17477', '11765', '3101267', '323951', 'C 7077', '113503',\n",
       "       '2648', '347069', 'PC 17757', '2653', 'STON/O 2. 3101293',\n",
       "       '349227', '27849', '367655', 'SC 1748', '113760', '350034',\n",
       "       '3101277', '350052', '350407', '28403', '244278', '240929',\n",
       "       'STON/O 2. 3101289', '341826', '4137', '315096', '28664', '347064',\n",
       "       '29106', '312992', '349222', '394140', 'STON/O 2. 3101269',\n",
       "       '343095', '28220', '250652', '28228', '345773', '349254',\n",
       "       'A/5. 13032', '315082', '347080', 'A/4. 34244', '2003', '250655',\n",
       "       '364851', 'SOTON/O.Q. 392078', '110564', '376564', 'SC/AH 3085',\n",
       "       'STON/O 2. 3101274', '13507', 'C.A. 18723', '345769', '347076',\n",
       "       '230434', '65306', '33638', '113794', '2666', '113786', '65303',\n",
       "       '113051', '17453', 'A/5 2817', '349240', '13509', '17464',\n",
       "       'F.C.C. 13531', '371060', '19952', '364506', '111320', '234360',\n",
       "       'A/S 2816', 'SOTON/O.Q. 3101306', '113792', '36209', '323592',\n",
       "       '315089', 'SC/AH Basle 541', '7553', '31027', '3460', '350060',\n",
       "       '3101298', '239854', 'A/5 3594', '4134', '11771', 'A.5. 18509',\n",
       "       '65304', 'SOTON/OQ 3101317', '113787', 'PC 17609', 'A/4 45380',\n",
       "       '36947', 'C.A. 6212', '350035', '315086', '364846', '330909',\n",
       "       '4135', '26360', '111427', 'C 4001', '382651', 'SOTON/OQ 3101316',\n",
       "       'PC 17473', 'PC 17603', '349209', '36967', 'C.A. 34260', '226875',\n",
       "       '349242', '12749', '349252', '2624', '2700', '367232',\n",
       "       'W./C. 14258', 'PC 17483', '3101296', '29104', '2641', '2690',\n",
       "       '315084', '113050', 'PC 17761', '364498', '13568', 'WE/P 5735',\n",
       "       '2908', '693', 'SC/PARIS 2146', '244358', '330979', '2620',\n",
       "       '347085', '113807', '11755', '345572', '372622', '349251',\n",
       "       '218629', 'SOTON/OQ 392082', 'SOTON/O.Q. 392087', 'A/4 48871',\n",
       "       '349205', '2686', '350417', 'S.W./PP 752', '11769', 'PC 17474',\n",
       "       '14312', 'A/4. 20589', '358585', '243880', '2689',\n",
       "       'STON/O 2. 3101286', '237789', '13049', '3411', '237565', '13567',\n",
       "       '14973', 'A./5. 3235', 'STON/O 2. 3101273', 'A/5 3902', '364848',\n",
       "       'SC/AH 29037', '248727', '2664', '349214', '113796', '364511',\n",
       "       '111426', '349910', '349246', '113804', 'SOTON/O.Q. 3101305',\n",
       "       '370377', '364512', '220845', '31028', '2659', '11753', '350029',\n",
       "       '54636', '36963', '219533', '349224', '334912', '27042', '347743',\n",
       "       '13214', '112052', '237668', 'STON/O 2. 3101292', '350050',\n",
       "       '349231', '13213', 'S.O./P.P. 751', 'CA. 2314', '349221', '8475',\n",
       "       '330919', '365226', '349223', '29751', '2623', '5727', '349210',\n",
       "       'STON/O 2. 3101285', '234686', '312993', 'A/5 3536', '19996',\n",
       "       '29750', 'F.C. 12750', 'C.A. 24580', '244270', '239856', '349912',\n",
       "       '342826', '4138', '330935', '6563', '349228', '350036', '24160',\n",
       "       '17474', '349256', '2672', '113800', '248731', '363592', '35852',\n",
       "       '348121', 'PC 17475', '36864', '350025', '223596', 'PC 17476',\n",
       "       'PC 17482', '113028', '7545', '250647', '348124', '34218', '36568',\n",
       "       '347062', '350048', '12233', '250643', '113806', '315094', '36866',\n",
       "       '236853', 'STON/O2. 3101271', '239855', '28425', '233639',\n",
       "       '349201', '349218', '16988', '376566', 'STON/O 2. 3101288',\n",
       "       '250648', '113773', '335097', '29103', '392096', '345780',\n",
       "       '349204', '350042', '29108', '363294', 'SOTON/O2 3101272', '2663',\n",
       "       '347074', '112379', '364850', '8471', '345781', '350047',\n",
       "       'S.O./P.P. 3', '2674', '29105', '347078', '383121', '36865',\n",
       "       '2687', '113501', 'W./C. 6607', 'SOTON/O.Q. 3101312', '374887',\n",
       "       '3101265', '12460', 'PC 17600', '349203', '28213', '17465',\n",
       "       '349244', '2685', '2625', '347089', '347063', '112050', '347087',\n",
       "       '248723', '3474', '28206', '364499', '112058', 'STON/O2. 3101290',\n",
       "       'S.C./PARIS 2079', 'C 7075', '315098', '19972', '368323', '367228',\n",
       "       '2671', '347468', '2223', 'PC 17756', '315097', '392092', '11774',\n",
       "       'SOTON/O2 3101287', '2683', '315090', 'C.A. 5547', '349213',\n",
       "       '347060', 'PC 17592', '392091', '113055', '2629', '350026',\n",
       "       '28134', '17466', '233866', '236852', 'SC/PARIS 2149', 'PC 17590',\n",
       "       '345777', '349248', '695', '345765', '2667', '349212', '349217',\n",
       "       '349257', '7552', 'C.A./SOTON 34068', 'SOTON/OQ 392076', '211536',\n",
       "       '112053', '111369', '370376'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Ticket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab5044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
